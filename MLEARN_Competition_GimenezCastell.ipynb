{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLEARN_Competition_GimenezCastell.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QzW43GdlCXoF",
        "Wn4TROMqCcUY",
        "uMVDRYGJBkgO"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzW43GdlCXoF"
      },
      "source": [
        "# Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdfF9Rz4nS1i"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "\n",
        "import sklearn.tree\n",
        "import sklearn.ensemble\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvdFxXlkwPIz",
        "outputId": "93f63d19-47da-47a1-edb5-96497fe67024"
      },
      "source": [
        "# Clone repository in order to get access locally to the datasets\n",
        "!rm -rf .git README.md\n",
        "!git clone -b playing-emsembled-methods https://github.com/sergio-gimenez/anomaly-4G-detection "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'anomaly-4G-detection'...\n",
            "remote: Enumerating objects: 147, done.\u001b[K\n",
            "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 147 (delta 80), reused 104 (delta 39), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (147/147), 26.08 MiB | 24.94 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiO_tVqEtbhr"
      },
      "source": [
        "train = pd.read_csv('anomaly-4G-detection/ML-MATT-CompetitionQT2021_train.csv', sep=';')\n",
        "test = pd.read_csv('anomaly-4G-detection/ML-MATT-CompetitionQT2021_test.xls', sep=';' )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pQIAxp_wxGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca670bde-d105-418c-c422-6402e3ceb0a0"
      },
      "source": [
        "# Separate labels from data \n",
        "X = train.drop('Unusual', axis='columns')#.to_numpy()\n",
        "y = train['Unusual']#.to_numpy()\n",
        "\n",
        "# We split the data into training and validation subsets (80% and 20%) in\n",
        "# order to validate our training\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X, y, \n",
        "                                                                train_size=0.8,\n",
        "                                                                random_state=1, stratify = y)\n",
        "X_test = test\n",
        "#X_train = X\n",
        "#y_train = y\n",
        "zeros = []\n",
        "ones = []\n",
        "for a in y_train:\n",
        "  if a == 0:\n",
        "    zeros.append(a)\n",
        "  else:\n",
        "    ones.append(1)\n",
        "print(len(zeros), len(ones), len(ones)+ len(zeros), y_train.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21377 8146 29523 (29523,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkMgA0YsluhJ"
      },
      "source": [
        "#Refactor time feature to minuts and cellName to unique identifier 1:1\n",
        "def getTimeInMinutes(x):\n",
        "  hh, mm  = x.split(\":\")\n",
        "  return int(hh)* 60 + int(mm)\n",
        "\n",
        "def createCellNameDictionary(data):\n",
        "  cellList = []\n",
        "  for i in data[\"CellName\"]:\n",
        "    cellList.append(i)\n",
        "  cellList = set(cellList)\n",
        "  cellDict = {}\n",
        "  for idx, value in enumerate(cellList):\n",
        "    cellDict[value]=idx\n",
        "  return cellDict\n",
        "\n",
        "def refactorFeaturesDataframe(data):\n",
        "  #data[\"Time\"] = data[\"Time\"].apply(lambda x: getTimeInMinutes(x))\n",
        "  data[\"TimeCos\"] = data[\"Time\"].apply(lambda x: math.cos(getTimeInMinutes(x)*math.pi/(12*60)))\n",
        "  data[\"TimeSin\"] = data[\"Time\"].apply(lambda x: math.sin(getTimeInMinutes(x)*math.pi/(12*60)))\n",
        "  del data[\"Time\"]\n",
        "\n",
        "  cellNameDict = createCellNameDictionary(data);\n",
        "  data[\"CellName\"] = data[\"CellName\"].apply(lambda x: cellNameDict[x])\n",
        "  print(data.head())\n",
        "  return data\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIoTgjuA0yak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe671426-74d4-4f20-d9e0-30aa8120be4a"
      },
      "source": [
        "#Refactoring data from features to useful values\n",
        "X_train = refactorFeaturesDataframe(X_train).to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "\n",
        "\n",
        "X_validation = refactorFeaturesDataframe(X_validation).to_numpy()\n",
        "y_validation = y_validation.to_numpy()\n",
        "\n",
        "X_test = refactorFeaturesDataframe(test).to_numpy()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       CellName  PRBUsageUL  PRBUsageDL  ...  maxUE_UL+DL   TimeCos   TimeSin\n",
            "14974        22      22.837       2.728  ...           12 -0.991445  0.130526\n",
            "5318         27       7.377       1.011  ...            7 -0.442289  0.896873\n",
            "31338         7       0.101       0.808  ...            4  0.442289  0.896873\n",
            "22493        16       2.425       9.701  ...           10 -0.831470  0.555570\n",
            "27949        19      22.938       3.335  ...           12 -0.923880  0.382683\n",
            "\n",
            "[5 rows x 14 columns]\n",
            "       CellName  PRBUsageUL  PRBUsageDL  ...  maxUE_UL+DL   TimeCos   TimeSin\n",
            "11936        26      0.2020      0.5050  ...            5 -0.555570  0.831470\n",
            "23788        20      4.0413      1.2222  ...            7  0.500000  0.866025\n",
            "29595        16      0.2020      0.8080  ...            3 -0.130526  0.991445\n",
            "29759        19      3.3674      0.5049  ...            6  0.831470  0.555570\n",
            "33580         5     12.4290      1.1120  ...            7  0.321439 -0.946930\n",
            "\n",
            "[5 rows x 14 columns]\n",
            "   CellName  PRBUsageUL  PRBUsageDL  ...  maxUE_UL+DL   TimeCos   TimeSin\n",
            "0         0      3.8177      1.5251  ...            6  0.707107  0.707107\n",
            "1        16      2.0210      3.3350  ...            9  0.608761 -0.793353\n",
            "2         8      0.5050      0.4040  ...            3 -0.991445  0.130526\n",
            "3         6      1.0110      0.5050  ...            3 -0.195090  0.980785\n",
            "4        19      4.0269      0.5104  ...            5 -0.555570 -0.831470\n",
            "\n",
            "[5 rows x 14 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn4TROMqCcUY"
      },
      "source": [
        "# Solving the Classification Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHDdmOgCuo_P"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from joblib import dump, load\n",
        "from google.colab import files\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "#if performVoting == 'y':\n",
        "  \n",
        "try:\n",
        "  clf_GS = load('anomaly-4G-detection/voting_model.joblib') \n",
        "\n",
        "except:\n",
        "  voting_clf = VotingClassifier( estimators=[ \n",
        "      ('xgb', XGBClassifier(random_state=1)),\n",
        "      ('dt', DecisionTreeClassifier(random_state=1)),\n",
        "      ('knn', KNeighborsClassifier())\n",
        "      ], voting='soft')\n",
        "\n",
        "  def xgb_f1(y, t, threshold=0.5):\n",
        "    t = t.get_label()\n",
        "    y_bin = (y > threshold).astype(int) # works for both type(y) == <class 'numpy.ndarray'> and type(y) == <class 'pandas.core.series.Series'>\n",
        "    return 'f1',f1_score(t,y_bin)\n",
        "\n",
        "\n",
        "  pipe = Pipeline(steps=[('std_slc', StandardScaler()),\n",
        "                              ('voting_clf', XGBClassifier(random_state=1, scale_pos_weight=7))])\n",
        "  \n",
        "  parameters = {\n",
        "  \"voting_clf__colsample_bytree\": uniform(0.05, 0.2),\n",
        "  \"voting_clf__min_child_weight\": randint(1, 5),\n",
        "  \"voting_clf__gamma\": uniform(0.35, 0.6),\n",
        "  \"voting_clf__learning_rate\": uniform(0.1, 0.3), # default 0.1 \n",
        "  \"voting_clf__max_depth\": randint(10, 30), # default 3\n",
        "  \"voting_clf__n_estimators\": randint(500, 1000), # default 100\n",
        "  \"voting_clf__subsample\": uniform(0.6, 0.99)\n",
        "  }\n",
        "\n",
        "  grid_params = {\n",
        "  \"voting_clf__colsample_bytree\": [0.1, 0.2],\n",
        "  \"voting_clf__min_child_weight\": [1],\n",
        "  \"voting_clf__gamma\": [0.35, 0.4, 0.5],\n",
        "  \"voting_clf__learning_rate\": [0.15, 0.2, 0.3], # default 0.1 \n",
        "  \"voting_clf__max_depth\": [15, 19, 21], # default 3\n",
        "  \"voting_clf__n_estimators\": [600, 700, 800], # default 100\n",
        "  \"voting_clf__subsample\": [0.932]\n",
        "  }\n",
        "\n",
        "  #clf_GS = GridSearchCV(estimator=pipe, param_grid=grid_params, n_jobs=10, verbose=1, cv=3 )\n",
        "  clf_GS = RandomizedSearchCV(estimator=pipe, param_distributions=parameters, n_jobs=10, verbose=1, cv=5, n_iter= 50 )\n",
        "  clf_GS.fit(X_train,y_train, voting_clf__eval_metric=xgb_f1)\n",
        "\n",
        "  #Save the model in a file and download locally.\n",
        "  dump(clf_GS, 'voting_model.joblib')\n",
        "  files.download('voting_model.joblib') "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6XZezYqNpOh"
      },
      "source": [
        "pred_train = clf_GS.predict(X_train)\n",
        "pred_val = clf_GS.predict(X_validation)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWVLG5ErZ4ZY",
        "outputId": "03d9a614-f62a-47de-b402-c39b5ec24cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "print(clf_GS.best_estimator_.named_steps[\"voting_clf\"].feature_importances_)\n",
        "print(clf_GS.best_estimator_.named_steps[\"voting_clf\"].get_booster().get_fscore())\n",
        "\n",
        "#thresholds = sort(clf_GS.best_estimator_.named_steps[\"voting_clf\"].feature_importances_)\n",
        "selection = SelectFromModel(clf_GS.best_estimator_.named_steps[\"voting_clf\"], threshold=0.1, prefit=True)\n",
        "select_X_train = selection.transform(X_train)\n",
        "selection_model = clf_GS\n",
        "selection_model.fit(select_X_train, y_train)\n",
        "pred_train = selection_model.predict(select_X_train)\n",
        "select_X_val = selection.transform(X_validation)\n",
        "pred_val = selection_model.predict(select_X_val)\n",
        "dump(clf_GS, 'selected_feature_model.joblib')\n",
        "files.download('selected_feature_model.joblib') "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0166639  0.13471697 0.10235471 0.00971994 0.04486122 0.00563823\n",
            " 0.00506799 0.03322988 0.41463506 0.03121206 0.03567908 0.13479647\n",
            " 0.01856771 0.01285673]\n",
            "{'f1': 393, 'f11': 42, 'f0': 66, 'f10': 14, 'f12': 25, 'f8': 411, 'f4': 944, 'f9': 11, 'f2': 341, 'f3': 520, 'f7': 610, 'f13': 13, 'f5': 301, 'f6': 169}\n",
            "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  9.6min\n",
            "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed: 27.3min\n",
            "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed: 50.4min\n",
            "[Parallel(n_jobs=10)]: Done 1230 tasks      | elapsed: 86.8min\n",
            "[Parallel(n_jobs=10)]: Done 1780 tasks      | elapsed: 119.0min\n",
            "[Parallel(n_jobs=10)]: Done 2430 tasks      | elapsed: 165.1min\n",
            "[Parallel(n_jobs=10)]: Done 2500 out of 2500 | elapsed: 170.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1b080d5a-bb76-4dd1-9f66-4e158c267728\", \"selected_feature_model.joblib\", 2728500)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luMnqSly3KZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a3442d-8ab4-4f98-ef8f-2bb29386ca5b"
      },
      "source": [
        "print(\"TRAINING\\n\" + classification_report(y_train, pred_train))\n",
        "print(\"\\nTESTING\\n\" + classification_report(y_validation, pred_val))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     21377\n",
            "           1       1.00      1.00      1.00      8146\n",
            "\n",
            "    accuracy                           1.00     29523\n",
            "   macro avg       1.00      1.00      1.00     29523\n",
            "weighted avg       1.00      1.00      1.00     29523\n",
            "\n",
            "\n",
            "TESTING\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      5344\n",
            "           1       1.00      0.99      0.99      2037\n",
            "\n",
            "    accuracy                           1.00      7381\n",
            "   macro avg       1.00      0.99      1.00      7381\n",
            "weighted avg       1.00      1.00      1.00      7381\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ3k3xOb3j2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c276b475-a1a2-42fe-e081-1cc1341e2216"
      },
      "source": [
        "train_error = 1. - accuracy_score(y_train, pred_train)\n",
        "train_cmat = confusion_matrix(y_train, pred_train)\n",
        "val_error = 1. - accuracy_score(y_validation, pred_val)\n",
        "val_cmat = confusion_matrix(y_validation, pred_val)\n",
        "\n",
        "print('train error: %f ' % train_error)\n",
        "print('train confusion matrix:')\n",
        "print(train_cmat)\n",
        "print('test error: %f ' % val_error)\n",
        "print('test confusion matrix:')\n",
        "print(val_cmat)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train error: 0.000542 \n",
            "train confusion matrix:\n",
            "[[21377     0]\n",
            " [   16  8130]]\n",
            "test error: 0.003794 \n",
            "test confusion matrix:\n",
            "[[5343    1]\n",
            " [  27 2010]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tbj-UBH5Piz"
      },
      "source": [
        "#pred_test = clf_GS.predict(X_test)\n",
        "pred_test = selection_model.predict(selection.transform(X_test))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMVDRYGJBkgO"
      },
      "source": [
        "# Submission Formatting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H-d7HbGA1I2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "789b5f0d-a79f-4d92-8335-1b95788bfb7a"
      },
      "source": [
        "%%shell\n",
        "# Create submission file if it does not exists\n",
        "file=predictions.csv\n",
        "if [ ! -e \"$file\" ] ; then\n",
        "    touch anomaly-4G-detection/\"$file\"\n",
        "fi"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9CouZll67HG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "0a2be1f0-0fd9-4d06-f498-f6f6c5ffd7f2"
      },
      "source": [
        "# Create index column in data frame object\n",
        "submission_dataframe = pd.DataFrame(np.arange(1, 9159), columns=['Id']) \n",
        "\n",
        "# Append predictions of test data as column\n",
        "submission_dataframe['Label'] = pred_test\n",
        "\n",
        "# Convert Data Frame object to CSV\n",
        "submission_dataframe.to_csv('predictions.csv', index=False)\n",
        "\n",
        "!mv predictions.csv anomaly-4G-detection/\n",
        "predictions = pd.read_csv('anomaly-4G-detection/predictions.csv')\n",
        "predictions"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9153</th>\n",
              "      <td>9154</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9154</th>\n",
              "      <td>9155</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9155</th>\n",
              "      <td>9156</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9156</th>\n",
              "      <td>9157</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9157</th>\n",
              "      <td>9158</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9158 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Id  Label\n",
              "0        1      1\n",
              "1        2      0\n",
              "2        3      0\n",
              "3        4      0\n",
              "4        5      1\n",
              "...    ...    ...\n",
              "9153  9154      0\n",
              "9154  9155      1\n",
              "9155  9156      0\n",
              "9156  9157      0\n",
              "9157  9158      0\n",
              "\n",
              "[9158 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWZoB4CM4Qbo"
      },
      "source": [
        "#!rm anomaly-4G-detection/predictions.csv"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASKJSoDN6Hhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4b99865-36da-4461-e530-6e2338ddec67"
      },
      "source": [
        "clf_GS.best_params_\n",
        "#print(clf_GS.grid_scores_)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'voting_clf__colsample_bytree': 0.08791176575309914,\n",
              " 'voting_clf__eta': 0.3546504236948929,\n",
              " 'voting_clf__gamma': 0.49579989534968655,\n",
              " 'voting_clf__learning_rate': 0.39249667840172153,\n",
              " 'voting_clf__max_depth': 26,\n",
              " 'voting_clf__min_child_weight': 2,\n",
              " 'voting_clf__n_estimators': 963,\n",
              " 'voting_clf__subsample': 0.8943470563917577}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}