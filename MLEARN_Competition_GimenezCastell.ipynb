{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLEARN_Competition_GimenezCastell.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QzW43GdlCXoF",
        "Wn4TROMqCcUY",
        "uMVDRYGJBkgO"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzW43GdlCXoF"
      },
      "source": [
        "# Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdfF9Rz4nS1i"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import sklearn.tree\n",
        "import sklearn.ensemble\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvdFxXlkwPIz",
        "outputId": "df6336f0-45cf-40dd-a03c-9ed3e45f42b6"
      },
      "source": [
        "# Clone repository in order to get access locally to the datasets\n",
        "!rm -rf .git README.md\n",
        "!git clone -b playing-emsembled-methods https://github.com/sergio-gimenez/anomaly-4G-detection . "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path '.' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkZG0vkAQiRr",
        "outputId": "7e76eaeb-ab1e-41a7-fd5f-9d3ebd964d84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 36\n",
            "drwxr-xr-x 1 root root 4096 Dec 30 15:25 .\n",
            "drwxr-xr-x 1 root root 4096 Dec 30 14:43 ..\n",
            "drwxr-xr-x 3 root root 4096 Dec 30 15:24 a\n",
            "drwxr-xr-x 4 root root 4096 Dec 30 15:21 anomaly-4G-detectiona\n",
            "drwxr-xr-x 3 root root 4096 Dec 30 15:22 anomaly-4G-detectionsd\n",
            "drwxr-xr-x 1 root root 4096 Dec 21 17:29 .config\n",
            "drwxr-xr-x 3 root root 4096 Dec 30 15:22 ds\n",
            "drwxr-xr-x 2 root root 4096 Dec 30 15:20 .ipynb_checkpoints\n",
            "drwxr-xr-x 1 root root 4096 Dec 21 17:29 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiO_tVqEtbhr"
      },
      "source": [
        "train = pd.read_csv('anomaly-4G-detection/ML-MATT-CompetitionQT2021_train.csv', sep=';')\n",
        "test = pd.read_csv('anomaly-4G-detection/ML-MATT-CompetitionQT2021_test.xls', sep=';' )"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pQIAxp_wxGk"
      },
      "source": [
        "# Separate labels from data \n",
        "X = train.drop('Unusual', axis='columns')#.to_numpy()\n",
        "y = train['Unusual']#.to_numpy()\n",
        "\n",
        "# We split the data into training and validation subsets (80% and 20%) in\n",
        "# order to validate our training\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X, y, \n",
        "                                                                train_size=0.8,\n",
        "                                                                random_state=1, stratify = y)\n",
        "X_test = test"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkMgA0YsluhJ"
      },
      "source": [
        "#Refactor time feature to minuts and cellName to unique identifier 1:1\n",
        "def getTimeInMinutes(x):\n",
        "  hh, mm  = x.split(\":\")\n",
        "  return int(hh)* 60 + int(mm)\n",
        "\n",
        "def createCellNameDictionary(data):\n",
        "  cellList = []\n",
        "  for i in data[\"CellName\"]:\n",
        "    cellList.append(i)\n",
        "  cellList = set(cellList)\n",
        "  cellDict = {}\n",
        "  for idx, value in enumerate(cellList):\n",
        "    cellDict[value]=idx\n",
        "  return cellDict\n",
        "\n",
        "def refactorFeaturesDataframe(data):\n",
        "  data[\"Time\"] = data[\"Time\"].apply(lambda x: getTimeInMinutes(x))\n",
        "  cellNameDict = createCellNameDictionary(data);\n",
        "  data[\"CellName\"] = data[\"CellName\"].apply(lambda x: cellNameDict[x])\n",
        "  return data\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIoTgjuA0yak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e49046-b1e1-48ef-8681-74c9b5187c82"
      },
      "source": [
        "#Refactoring data from features to useful values\n",
        "X_train = refactorFeaturesDataframe(X_train).to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "\n",
        "X_validation = refactorFeaturesDataframe(X_validation).to_numpy()\n",
        "y_validation = y_validation.to_numpy()\n",
        "\n",
        "X_test = refactorFeaturesDataframe(test).to_numpy()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn4TROMqCcUY"
      },
      "source": [
        "# Solving the Classification Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSk27jtY2xyB",
        "outputId": "ee47d3e7-9b25-45c6-b20a-786fcfed9762"
      },
      "source": [
        "clf = sklearn.tree.DecisionTreeClassifier(random_state=1)\n",
        "pipe = Pipeline(steps=[('std_slc', StandardScaler()),\n",
        "                           ('dec_tree', clf)])\n",
        "\n",
        "n_components = list(range(1,X_train.shape[1]+1,2))\n",
        "criterion = ['gini', 'entropy']\n",
        "max_depth = [None,2,8,12]\n",
        "min_samples_split = [2,4,8,10]\n",
        "min_samples_leaf = [1,2,5]\n",
        "\n",
        "parameters = dict(dec_tree__criterion=criterion,\n",
        "                      dec_tree__min_samples_split=min_samples_split,\n",
        "                      dec_tree__min_samples_leaf=min_samples_leaf,\n",
        "                      dec_tree__max_depth=max_depth)\n",
        "#clf_GS = GridSearchCV(pipe, parameters)\n",
        "#clf_GS.fit(X_train, y_train)\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=1, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6s3bW7121UD"
      },
      "source": [
        "#pred_train = clf_GS.predict(X_train)\n",
        "#pred_val = clf_GS.predict(X_validation)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM1MYz_vMXSu"
      },
      "source": [
        "# AdaBoost with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MDrmIf9HNpE"
      },
      "source": [
        "#ADABOOST\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from joblib import dump, load\n",
        "\n",
        "adaboost_mode_file = 'anomaly-4G-detection/adaboost_model.joblib'\n",
        "try:\n",
        "  clf_GS = load(adaboost_mode_file) \n",
        "  print(clf_GS)\n",
        "  input(\"Press Enter to continue...\")\n",
        "\n",
        "except:\n",
        "  clf = AdaBoostClassifier(random_state=1)\n",
        "  pipe = Pipeline(steps=[('std_slc', StandardScaler()),\n",
        "                            ('ada', clf)])\n",
        "  n_components = list(range(1,X_train.shape[1]+1,2))\n",
        "  n_estimators = [100, 150, 200, 250]\n",
        "  learning_rate = [0.01,0.1,1,10]\n",
        "  parameters = dict(ada__n_estimators=n_estimators,\n",
        "                        ada__learning_rate=learning_rate\n",
        "                    )\n",
        "  clf_GS = GridSearchCV(pipe, parameters)\n",
        "  clf_GS.fit(X_train, y_train)\n",
        "  dump(clf_GS, adaboost_mode_file) \n",
        "\n",
        "pred_train = clf_GS.predict(X_train)\n",
        "pred_val = clf_GS.predict(X_validation)\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P31bEittujim"
      },
      "source": [
        "# Voting Classifier with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHDdmOgCuo_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "afba93dc-45af-4f08-b410-12ce820c7ce8"
      },
      "source": [
        "'''\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "eclf = VotingClassifier( estimators=[ \n",
        "    ('svm', SVC(probability=True)),\n",
        "    ('lr', LogisticRegression()),\n",
        "    ], voting='soft')\n",
        "\n",
        "#Use the key for the classifier followed by __ and the attribute\n",
        "params = {'lr__C': [1.0, 100.0],\n",
        "      'svm__C': [2,3,4],}\n",
        "\n",
        "grid = GridSearchCV( estimator=eclf, param_grid=params, cv=2)\n",
        "\n",
        "grid.fit(X,y)\n",
        "'''"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-f4cf8f7ea917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m eclf = VotingClassifier( estimators=[ \n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'svm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     ], voting='soft')\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SVC' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6XZezYqNpOh"
      },
      "source": [
        "pred_train = clf_GS.predict(X_train)\n",
        "pred_val = clf_GS.predict(X_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luMnqSly3KZq",
        "outputId": "68cfbbef-ed87-43f5-8ce9-a83ebd2b956d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"TRAINING\\n\" + classification_report(y_train, pred_train))\n",
        "print(\"\\nTESTING\\n\" + classification_report(y_validation, pred_val))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.99      0.93     21377\n",
            "           1       0.95      0.62      0.75      8146\n",
            "\n",
            "    accuracy                           0.89     29523\n",
            "   macro avg       0.91      0.80      0.84     29523\n",
            "weighted avg       0.89      0.89      0.88     29523\n",
            "\n",
            "\n",
            "TESTING\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.99      0.93      5344\n",
            "           1       0.96      0.63      0.76      2037\n",
            "\n",
            "    accuracy                           0.89      7381\n",
            "   macro avg       0.92      0.81      0.85      7381\n",
            "weighted avg       0.90      0.89      0.88      7381\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ3k3xOb3j2U",
        "outputId": "a43dd0cf-6cd0-4de6-a805-32a88f132e71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_error = 1. - accuracy_score(y_train, pred_train)\n",
        "train_cmat = confusion_matrix(y_train, pred_train)\n",
        "val_error = 1. - accuracy_score(y_validation, pred_val)\n",
        "val_cmat = confusion_matrix(y_validation, pred_val)\n",
        "\n",
        "print('train error: %f ' % train_error)\n",
        "print('train confusion matrix:')\n",
        "print(train_cmat)\n",
        "print('test error: %f ' % val_error)\n",
        "print('test confusion matrix:')\n",
        "print(val_cmat)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train error: 0.113945 \n",
            "train confusion matrix:\n",
            "[[21130   247]\n",
            " [ 3117  5029]]\n",
            "test error: 0.109064 \n",
            "test confusion matrix:\n",
            "[[5294   50]\n",
            " [ 755 1282]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tbj-UBH5Piz"
      },
      "source": [
        "pred_test = clf_GS.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMVDRYGJBkgO"
      },
      "source": [
        "# Submission Formatting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H-d7HbGA1I2"
      },
      "source": [
        "%%shell\n",
        "# Create submission file if it does not exists\n",
        "file=predictions.csv\n",
        "if [ ! -e \"$file\" ] ; then\n",
        "    touch anomaly-4G-detection/\"$file\"\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9CouZll67HG"
      },
      "source": [
        "# Create index column in data frame object\n",
        "submission_dataframe = pd.DataFrame(np.arange(1, 9159), columns=['Id']) \n",
        "\n",
        "# Append predictions of test data as column\n",
        "submission_dataframe['Label'] = pred_test\n",
        "\n",
        "# Convert Data Frame object to CSV\n",
        "submission_dataframe.to_csv('predictions.csv', index=False)\n",
        "\n",
        "!mv predictions.csv anomaly-4G-detection/\n",
        "predictions = pd.read_csv('anomaly-4G-detection/predictions.csv')\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWZoB4CM4Qbo"
      },
      "source": [
        "#!rm anomaly-4G-detection/predictions.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASKJSoDN6Hhx"
      },
      "source": [
        "clf_GS.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}