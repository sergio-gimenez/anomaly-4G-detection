{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLEARN_Competition_GimenezCastell.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzW43GdlCXoF"
      },
      "source": [
        "# Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdfF9Rz4nS1i"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "\n",
        "import sklearn.tree\n",
        "import sklearn.ensemble\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvdFxXlkwPIz",
        "outputId": "6633a3a4-dc17-4b27-ce68-75c03281cf65"
      },
      "source": [
        "# Clone repository in order to get access locally to the datasets\n",
        "!rm -rf .git README.md\n",
        "!git clone -b playing-emsembled-methods https://github.com/sergio-gimenez/anomaly-4G-detection "
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'anomaly-4G-detection' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiO_tVqEtbhr"
      },
      "source": [
        "train = pd.read_csv('anomaly-4G-detection/ML-MATT-CompetitionQT2021_train.csv', sep=';')\n",
        "test = pd.read_csv('anomaly-4G-detection/ML-MATT-CompetitionQT2021_test.xls', sep=';' )"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pQIAxp_wxGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae05158d-ea93-493b-99e4-2793874171e8"
      },
      "source": [
        "# Separate labels from data \n",
        "X = train.drop('Unusual', axis='columns')#.to_numpy()\n",
        "y = train['Unusual']#.to_numpy()\n",
        "\n",
        "# We split the data into training and validation subsets (80% and 20%) in\n",
        "# order to validate our training\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X, y, \n",
        "                                                                train_size=0.8,\n",
        "                                                                random_state=1, stratify = y)\n",
        "X_test = test\n",
        "#X_train = X\n",
        "#y_train = y\n",
        "zeros = []\n",
        "ones = []\n",
        "for a in y_train:\n",
        "  if a == 0:\n",
        "    zeros.append(a)\n",
        "  else:\n",
        "    ones.append(1)\n",
        "print(len(zeros), len(ones), len(ones)+ len(zeros), y_train.shape)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21377 8146 29523 (29523,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkMgA0YsluhJ"
      },
      "source": [
        "#Refactor time feature to minuts and cellName to unique identifier 1:1\n",
        "def getTimeInMinutes(x):\n",
        "  hh, mm  = x.split(\":\")\n",
        "  return int(hh)* 60 + int(mm)\n",
        "\n",
        "def createCellNameDictionary(data):\n",
        "  cellList = []\n",
        "  for i in data[\"CellName\"]:\n",
        "    cellList.append(i)\n",
        "  cellList = set(cellList)\n",
        "  cellDict = {}\n",
        "  for idx, value in enumerate(cellList):\n",
        "    cellDict[value]=idx\n",
        "  return cellDict\n",
        "\n",
        "def refactorFeaturesDataframe(data):\n",
        "  #data[\"Time\"] = data[\"Time\"].apply(lambda x: getTimeInMinutes(x))\n",
        "  data[\"TimeCos\"] = data[\"Time\"].apply(lambda x: math.cos(getTimeInMinutes(x)*math.pi/(12*60)))\n",
        "  data[\"TimeSin\"] = data[\"Time\"].apply(lambda x: math.sin(getTimeInMinutes(x)*math.pi/(12*60)))\n",
        "  del data[\"Time\"]\n",
        "\n",
        "  cellNameDict = createCellNameDictionary(data);\n",
        "  data[\"CellName\"] = data[\"CellName\"].apply(lambda x: cellNameDict[x])\n",
        "  print(data.head())\n",
        "  return data\n"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIoTgjuA0yak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcba09fc-1d94-42a2-b50f-bb7922b9a3f3"
      },
      "source": [
        "#Refactoring data from features to useful values\n",
        "X_train = refactorFeaturesDataframe(X_train).to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "\n",
        "\n",
        "X_validation = refactorFeaturesDataframe(X_validation).to_numpy()\n",
        "y_validation = y_validation.to_numpy()\n",
        "\n",
        "X_test = refactorFeaturesDataframe(test).to_numpy()"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       CellName  PRBUsageUL  PRBUsageDL  ...  maxUE_UL+DL   TimeCos   TimeSin\n",
            "14974        19      22.837       2.728  ...           12 -0.991445  0.130526\n",
            "5318         27       7.377       1.011  ...            7 -0.442289  0.896873\n",
            "31338        20       0.101       0.808  ...            4  0.442289  0.896873\n",
            "22493        24       2.425       9.701  ...           10 -0.831470  0.555570\n",
            "27949        15      22.938       3.335  ...           12 -0.923880  0.382683\n",
            "\n",
            "[5 rows x 14 columns]\n",
            "       CellName  PRBUsageUL  PRBUsageDL  ...  maxUE_UL+DL   TimeCos   TimeSin\n",
            "11936        17      0.2020      0.5050  ...            5 -0.555570  0.831470\n",
            "23788        15      4.0413      1.2222  ...            7  0.500000  0.866025\n",
            "29595         0      0.2020      0.8080  ...            3 -0.130526  0.991445\n",
            "29759         9      3.3674      0.5049  ...            6  0.831470  0.555570\n",
            "33580        16     12.4290      1.1120  ...            7  0.321439 -0.946930\n",
            "\n",
            "[5 rows x 14 columns]\n",
            "   CellName  PRBUsageUL  PRBUsageDL  ...  maxUE_UL+DL   TimeCos   TimeSin\n",
            "0         7      3.8177      1.5251  ...            6  0.707107  0.707107\n",
            "1         0      2.0210      3.3350  ...            9  0.608761 -0.793353\n",
            "2        30      0.5050      0.4040  ...            3 -0.991445  0.130526\n",
            "3        18      1.0110      0.5050  ...            3 -0.195090  0.980785\n",
            "4         9      4.0269      0.5104  ...            5 -0.555570 -0.831470\n",
            "\n",
            "[5 rows x 14 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn4TROMqCcUY"
      },
      "source": [
        "# Solving the Classification Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHDdmOgCuo_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "fc89ff73-33e1-497f-9c0d-9ec0b715bd43"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from joblib import dump, load\n",
        "from google.colab import files\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "#if performVoting == 'y':\n",
        "  \n",
        "try:\n",
        "  clf_GS = load('anomaly-4G-detection/voting_model.joblib') \n",
        "\n",
        "except:\n",
        "  voting_clf = VotingClassifier( estimators=[ \n",
        "      ('xgb', XGBClassifier(random_state=1)),\n",
        "      ('dt', DecisionTreeClassifier(random_state=1)),\n",
        "      ('knn', KNeighborsClassifier())\n",
        "      ], voting='soft')\n",
        "\n",
        "  def xgb_f1(y, t, threshold=0.5):\n",
        "    t = t.get_label()\n",
        "    y_bin = (y > threshold).astype(int) # works for both type(y) == <class 'numpy.ndarray'> and type(y) == <class 'pandas.core.series.Series'>\n",
        "    return 'f1',f1_score(t,y_bin)\n",
        "\n",
        "  pipe = Pipeline(steps=[('std_slc', StandardScaler()),\n",
        "                         ('voting_clf', XGBClassifier(random_state=1,\n",
        "                                                      #scale_pos_weight=7,\n",
        "                                                      #colsample_bytree= 0.053381469489678104,\n",
        "                                                      #eta= 0.20289460663803338,\n",
        "                                                      #gamma= 0.88723107873764,\n",
        "                                                      #learning_rate= 0.15455380920536027,\n",
        "                                                      #max_depth= 26,\n",
        "                                                      #min_child_weight= 1,\n",
        "                                                      #n_estimators= 565,\n",
        "                                                      #subsample= 0.9738168894035317\n",
        "                                                      ))])\n",
        "  \n",
        "  parameters = {\n",
        "   'voting_clf__eta'    : uniform(0.17, 0.25),\n",
        "   \"voting_clf__colsample_bytree\": uniform(0.5, 0.99),\n",
        "   \"voting_clf__min_child_weight\": randint(1, 5),\n",
        "   \"voting_clf__gamma\": uniform(0.35, 0.6),\n",
        "   \"voting_clf__learning_rate\": uniform(0.1, 0.2), # default 0.1 \n",
        "   \"voting_clf__max_depth\": randint(20, 30), # default 3\n",
        "   \"voting_clf__n_estimators\": randint(500, 1000), # default 100\n",
        "   \"voting_clf__subsample\": uniform(0.9, 0.99),\n",
        "   \"voting_clf__reg_alpha\": [0, 0.001, 0.005, 0.01, 0.05],\n",
        "   \"voting_clf__reg_lambda\": [1e-5, 1e-2, 0.1, 1, 100],\n",
        "   \"voting_clf__scale_pos_weight\": randint(6, 9)\n",
        "  }\n",
        "\n",
        "  # grid_params = {\n",
        "  # \"voting_clf__colsample_bytree\": [0.1, 0.2],\n",
        "  # \"voting_clf__min_child_weight\": [1],\n",
        "  # \"voting_clf__gamma\": [0.35, 0.4, 0.5],\n",
        "  # \"voting_clf__learning_rate\": [0.15, 0.2, 0.3], # default 0.1 \n",
        "  # \"voting_clf__max_depth\": [15, 19, 21], # default 3\n",
        "  # \"voting_clf__n_estimators\": [600, 700, 800], # default 100\n",
        "  # \"voting_clf__subsample\": [0.932]\n",
        "  # }\n",
        "\n",
        "  # parameters = {'voting_clf__colsample_bytree': 0.053381469489678104,\n",
        "  # 'voting_clf__eta': 0.20289460663803338,\n",
        "  # 'voting_clf__gamma': 0.88723107873764,\n",
        "  # 'voting_clf__learning_rate': 0.15455380920536027,\n",
        "  # 'voting_clf__max_depth': 26,\n",
        "  # 'voting_clf__min_child_weight': 1,\n",
        "  # 'voting_clf__n_estimators': 565,\n",
        "  # 'voting_clf__subsample': 0.9738168894035317}\n",
        "\n",
        "  #clf_GS = GridSearchCV(estimator=pipe, param_grid=grid_params, n_jobs=10, verbose=1, cv=3 )\n",
        "  clf_GS = RandomizedSearchCV(estimator=pipe, param_distributions=parameters, n_jobs=10, verbose=1, cv=3, n_iter= 500)\n",
        "  clf_GS.fit(X_train, y_train)\n",
        "\n",
        "  #Save the model in a file and download locally.\n",
        "  dump(clf_GS, 'voting_model.joblib')\n",
        "  files.download('voting_model.joblib') "
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  6.4min\n",
            "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed: 17.0min\n",
            "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed: 30.8min\n",
            "[Parallel(n_jobs=10)]: Done 1230 tasks      | elapsed: 39.5min\n",
            "[Parallel(n_jobs=10)]: Done 1500 out of 1500 | elapsed: 55.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_91c97216-edc1-4c8b-9741-d5748bb334ec\", \"voting_model.joblib\", 2997662)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6XZezYqNpOh"
      },
      "source": [
        "pred_train = clf_GS.predict(X_train)\n",
        "pred_val = clf_GS.predict(X_validation)"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luMnqSly3KZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3eaa8a5-b4ee-4ba1-c775-db1b38cf8a7a"
      },
      "source": [
        "print(\"TRAINING\\n\" + classification_report(y_train, pred_train))\n",
        "print(\"\\nTESTING\\n\" + classification_report(y_validation, pred_val))"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     21377\n",
            "           1       1.00      1.00      1.00      8146\n",
            "\n",
            "    accuracy                           1.00     29523\n",
            "   macro avg       1.00      1.00      1.00     29523\n",
            "weighted avg       1.00      1.00      1.00     29523\n",
            "\n",
            "\n",
            "TESTING\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      5344\n",
            "           1       0.99      0.98      0.98      2037\n",
            "\n",
            "    accuracy                           0.99      7381\n",
            "   macro avg       0.99      0.99      0.99      7381\n",
            "weighted avg       0.99      0.99      0.99      7381\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ3k3xOb3j2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "065c40ad-1959-43a6-f533-54496504299a"
      },
      "source": [
        "train_error = 1. - accuracy_score(y_train, pred_train)\n",
        "train_cmat = confusion_matrix(y_train, pred_train)\n",
        "val_error = 1. - accuracy_score(y_validation, pred_val)\n",
        "val_cmat = confusion_matrix(y_validation, pred_val)\n",
        "\n",
        "print('train error: %f ' % train_error)\n",
        "print('train confusion matrix:')\n",
        "print(train_cmat)\n",
        "print('test error: %f ' % val_error)\n",
        "print('test confusion matrix:')\n",
        "print(val_cmat)"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train error: 0.000000 \n",
            "train confusion matrix:\n",
            "[[21377     0]\n",
            " [    0  8146]]\n",
            "test error: 0.008806 \n",
            "test confusion matrix:\n",
            "[[5327   17]\n",
            " [  48 1989]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAZGYxcSfbZO",
        "outputId": "75b5b5d3-e6b2-42e9-c3e5-5130e0fae07b"
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "#print(clf_GS.best_estimator_.named_steps[\"voting_clf\"].feature_importances_)\n",
        "#print(clf_GS.best_estimator_.named_steps[\"voting_clf\"].get_booster().get_fscore())\n",
        "best_params = {k: [v] for k, v in clf_GS.best_params_.items()}\n",
        "thresholds = np.sort(clf_GS.best_estimator_.named_steps[\"voting_clf\"].feature_importances_)\n",
        "print('Thresholds',thresholds, '\\n')\n",
        "print('Best Params', best_params)\n",
        "\n",
        "i = 0\n",
        "current_error = 100.0\n",
        "best_th = 0\n",
        "for thresh in thresholds:\n",
        "  new_X_train = X_train\n",
        "  selection = SelectFromModel(clf_GS.best_estimator_.named_steps[\"voting_clf\"], threshold=thresh, prefit=True)\n",
        "  select_X_train = selection.transform(new_X_train)\n",
        "\n",
        "  selection_model = RandomizedSearchCV(estimator=pipe, param_distributions=best_params, n_jobs=10, verbose=1, cv=3, n_iter= 1)\n",
        "  selection_model.fit(select_X_train, y_train)\n",
        "  #dump(clf_GS, '%dselected_feature_model.joblib' % i)\n",
        "  #files.download('%dselected_feature_model.joblib' % i) \n",
        "  pred_train = selection_model.predict(select_X_train)\n",
        "  print(X_validation.shape, X_train.shape)\n",
        "  select_X_val = selection.transform(X_validation)\n",
        "  pred_val = selection_model.predict(select_X_val)\n",
        "  \n",
        "  i = i + 1\n",
        "\n",
        "  train_error = 1. - accuracy_score(y_train, pred_train)\n",
        "  train_cmat = confusion_matrix(y_train, pred_train)\n",
        "  val_error = 1. - accuracy_score(y_validation, pred_val)\n",
        "  val_cmat = confusion_matrix(y_validation, pred_val)\n",
        "\n",
        "  print(\"Threshold: %f \\n\" % thresh)\n",
        "  print('train error: %f ' % train_error)\n",
        "  print('train confusion matrix:')\n",
        "  print(train_cmat)\n",
        "  print('test error: %f ' % val_error)\n",
        "  print('test confusion matrix:')\n",
        "  print(val_cmat)\n",
        "  if val_error < current_error:\n",
        "    current_error = val_error\n",
        "    best_th = thresh\n",
        "\n",
        "print('Best th:', best_th)\n",
        "print('current error :', best_th)"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thresholds [0.01247077 0.01711424 0.0241311  0.02551129 0.02926498 0.03122059\n",
            " 0.03454302 0.03709779 0.04886748 0.05350886 0.06710359 0.07660205\n",
            " 0.13638878 0.40617552] \n",
            "\n",
            "Best Params {'voting_clf__colsample_bytree': [0.5679080291606311], 'voting_clf__eta': [0.25669249083545453], 'voting_clf__gamma': [0.3664509736859072], 'voting_clf__learning_rate': [0.14474841574499428], 'voting_clf__max_depth': [20], 'voting_clf__min_child_weight': [2], 'voting_clf__n_estimators': [704], 'voting_clf__reg_alpha': [0], 'voting_clf__reg_lambda': [0.1], 'voting_clf__scale_pos_weight': [8], 'voting_clf__subsample': [0.9858685418924441]}\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:   59.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7381, 14) (29523, 14)\n",
            "Threshold: 0.012471 \n",
            "\n",
            "train error: 0.000000 \n",
            "train confusion matrix:\n",
            "[[21377     0]\n",
            " [    0  8146]]\n",
            "test error: 0.008806 \n",
            "test confusion matrix:\n",
            "[[5327   17]\n",
            " [  48 1989]]\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:   58.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7381, 14) (29523, 14)\n",
            "Threshold: 0.017114 \n",
            "\n",
            "train error: 0.000000 \n",
            "train confusion matrix:\n",
            "[[21377     0]\n",
            " [    0  8146]]\n",
            "test error: 0.008129 \n",
            "test confusion matrix:\n",
            "[[5324   20]\n",
            " [  40 1997]]\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:   52.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7381, 14) (29523, 14)\n",
            "Threshold: 0.024131 \n",
            "\n",
            "train error: 0.000000 \n",
            "train confusion matrix:\n",
            "[[21377     0]\n",
            " [    0  8146]]\n",
            "test error: 0.007587 \n",
            "test confusion matrix:\n",
            "[[5328   16]\n",
            " [  40 1997]]\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:   51.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7381, 14) (29523, 14)\n",
            "Threshold: 0.025511 \n",
            "\n",
            "train error: 0.000000 \n",
            "train confusion matrix:\n",
            "[[21377     0]\n",
            " [    0  8146]]\n",
            "test error: 0.007858 \n",
            "test confusion matrix:\n",
            "[[5327   17]\n",
            " [  41 1996]]\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:   47.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7381, 14) (29523, 14)\n",
            "Threshold: 0.029265 \n",
            "\n",
            "train error: 0.000000 \n",
            "train confusion matrix:\n",
            "[[21377     0]\n",
            " [    0  8146]]\n",
            "test error: 0.007316 \n",
            "test confusion matrix:\n",
            "[[5330   14]\n",
            " [  40 1997]]\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:   47.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7381, 14) (29523, 14)\n",
            "Threshold: 0.031221 \n",
            "\n",
            "train error: 0.000000 \n",
            "train confusion matrix:\n",
            "[[21377     0]\n",
            " [    0  8146]]\n",
            "test error: 0.007723 \n",
            "test confusion matrix:\n",
            "[[5329   15]\n",
            " [  42 1995]]\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:   43.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7381, 14) (29523, 14)\n",
            "Threshold: 0.034543 \n",
            "\n",
            "train error: 0.000000 \n",
            "train confusion matrix:\n",
            "[[21377     0]\n",
            " [    0  8146]]\n",
            "test error: 0.005690 \n",
            "test confusion matrix:\n",
            "[[5332   12]\n",
            " [  30 2007]]\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:   38.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7381, 14) (29523, 14)\n",
            "Threshold: 0.037098 \n",
            "\n",
            "train error: 0.000000 \n",
            "train confusion matrix:\n",
            "[[21377     0]\n",
            " [    0  8146]]\n",
            "test error: 0.005284 \n",
            "test confusion matrix:\n",
            "[[5333   11]\n",
            " [  28 2009]]\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:   38.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7381, 14) (29523, 14)\n",
            "Threshold: 0.048867 \n",
            "\n",
            "train error: 0.000000 \n",
            "train confusion matrix:\n",
            "[[21377     0]\n",
            " [    0  8146]]\n",
            "test error: 0.006232 \n",
            "test confusion matrix:\n",
            "[[5335    9]\n",
            " [  37 2000]]\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:   33.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7381, 14) (29523, 14)\n",
            "Threshold: 0.053509 \n",
            "\n",
            "train error: 0.000000 \n",
            "train confusion matrix:\n",
            "[[21377     0]\n",
            " [    0  8146]]\n",
            "test error: 0.004606 \n",
            "test confusion matrix:\n",
            "[[5339    5]\n",
            " [  29 2008]]\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:   34.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7381, 14) (29523, 14)\n",
            "Threshold: 0.067104 \n",
            "\n",
            "train error: 0.000000 \n",
            "train confusion matrix:\n",
            "[[21377     0]\n",
            " [    0  8146]]\n",
            "test error: 0.004877 \n",
            "test confusion matrix:\n",
            "[[5336    8]\n",
            " [  28 2009]]\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:   28.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7381, 14) (29523, 14)\n",
            "Threshold: 0.076602 \n",
            "\n",
            "train error: 0.003658 \n",
            "train confusion matrix:\n",
            "[[21269   108]\n",
            " [    0  8146]]\n",
            "test error: 0.006639 \n",
            "test confusion matrix:\n",
            "[[5315   29]\n",
            " [  20 2017]]\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:   27.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7381, 14) (29523, 14)\n",
            "Threshold: 0.136389 \n",
            "\n",
            "train error: 0.005724 \n",
            "train confusion matrix:\n",
            "[[21211   166]\n",
            " [    3  8143]]\n",
            "test error: 0.007045 \n",
            "test confusion matrix:\n",
            "[[5307   37]\n",
            " [  15 2022]]\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:   24.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7381, 14) (29523, 14)\n",
            "Threshold: 0.406176 \n",
            "\n",
            "train error: 0.017884 \n",
            "train confusion matrix:\n",
            "[[21194   183]\n",
            " [  345  7801]]\n",
            "test error: 0.020458 \n",
            "test confusion matrix:\n",
            "[[5300   44]\n",
            " [ 107 1930]]\n",
            "Best th: 0.053508863\n",
            "current error : 0.053508863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrbsXcTbgboA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "90266873-a374-4f92-c0f9-ee555adacde2"
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "#print(clf_GS.best_estimator_.named_steps[\"voting_clf\"].feature_importances_)\n",
        "#print(clf_GS.best_estimator_.named_steps[\"voting_clf\"].get_booster().get_fscore())\n",
        "\n",
        "thresholds = np.sort(clf_GS.best_estimator_.named_steps[\"voting_clf\"].feature_importances_)\n",
        "print(thresholds)\n",
        "i = 0\n",
        "new_X_train = X_train\n",
        "selection = SelectFromModel(clf_GS.best_estimator_.named_steps[\"voting_clf\"], threshold=best_th , prefit=True)\n",
        "select_X_train = selection.transform(new_X_train)\n",
        "\n",
        "selection_model = RandomizedSearchCV(estimator=pipe, param_distributions=best_params, n_jobs=10, verbose=1, cv=3, n_iter= 1)\n",
        "selection_model.fit(select_X_train, y_train)\n",
        "dump(clf_GS, '%dselected_feature_model.joblib' % i)\n",
        "files.download('%dselected_feature_model.joblib' % i) \n",
        "pred_train = selection_model.predict(select_X_train)\n",
        "select_X_val = selection.transform(X_validation)\n",
        "pred_val = selection_model.predict(select_X_val)\n",
        "\n",
        "i = i + 1\n",
        "\n",
        "train_error = 1. - accuracy_score(y_train, pred_train)\n",
        "train_cmat = confusion_matrix(y_train, pred_train)\n",
        "val_error = 1. - accuracy_score(y_validation, pred_val)\n",
        "val_cmat = confusion_matrix(y_validation, pred_val)\n",
        "\n",
        "print(\"Threshold: %f \\n\" % thresh)\n",
        "print('train error: %f ' % train_error)\n",
        "print('train confusion matrix:')\n",
        "print(train_cmat)\n",
        "print('test error: %f ' % val_error)\n",
        "print('test confusion matrix:')\n",
        "print(val_cmat)"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01247077 0.01711424 0.0241311  0.02551129 0.02926498 0.03122059\n",
            " 0.03454302 0.03709779 0.04886748 0.05350886 0.06710359 0.07660205\n",
            " 0.13638878 0.40617552]\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:   33.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6289dd3a-a3e3-40fa-bb1c-82cd0ef9dd7d\", \"0selected_feature_model.joblib\", 2997662)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Threshold: 0.406176 \n",
            "\n",
            "train error: 0.000000 \n",
            "train confusion matrix:\n",
            "[[21377     0]\n",
            " [    0  8146]]\n",
            "test error: 0.004606 \n",
            "test confusion matrix:\n",
            "[[5339    5]\n",
            " [  29 2008]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tbj-UBH5Piz"
      },
      "source": [
        "#pred_test = clf_GS.predict(X_test)\n",
        "select_X_test = selection.transform(X_test)\n",
        "pred_test = selection_model.predict(select_X_test)\n",
        "#files.download('anomaly-4G-detection/predictions.csv')"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMVDRYGJBkgO"
      },
      "source": [
        "# Submission Formatting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H-d7HbGA1I2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e89cd79-2d0b-4955-8499-463faa1d611f"
      },
      "source": [
        "%%shell\n",
        "# Create submission file if it does not exists\n",
        "file=predictions.csv\n",
        "if [ ! -e \"$file\" ] ; then\n",
        "    touch anomaly-4G-detection/\"$file\"\n",
        "fi"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9CouZll67HG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "a88ef53a-fae7-4150-f605-39318f14172c"
      },
      "source": [
        "# Create index column in data frame object\n",
        "submission_dataframe = pd.DataFrame(np.arange(1, 9159), columns=['Id']) \n",
        "\n",
        "# Append predictions of test data as column\n",
        "submission_dataframe['Label'] = pred_test\n",
        "\n",
        "# Convert Data Frame object to CSV\n",
        "submission_dataframe.to_csv('predictions.csv', index=False)\n",
        "\n",
        "!mv predictions.csv anomaly-4G-detection/\n",
        "predictions = pd.read_csv('anomaly-4G-detection/predictions.csv')\n",
        "predictions"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9153</th>\n",
              "      <td>9154</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9154</th>\n",
              "      <td>9155</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9155</th>\n",
              "      <td>9156</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9156</th>\n",
              "      <td>9157</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9157</th>\n",
              "      <td>9158</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9158 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Id  Label\n",
              "0        1      1\n",
              "1        2      0\n",
              "2        3      0\n",
              "3        4      0\n",
              "4        5      1\n",
              "...    ...    ...\n",
              "9153  9154      0\n",
              "9154  9155      1\n",
              "9155  9156      0\n",
              "9156  9157      0\n",
              "9157  9158      0\n",
              "\n",
              "[9158 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWZoB4CM4Qbo"
      },
      "source": [
        "#!rm anomaly-4G-detection/predictions.csv"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASKJSoDN6Hhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afb79f52-c329-49c6-b274-a2eea5583937"
      },
      "source": [
        "clf_GS.best_params_\n",
        "#print(clf_GS.grid_scores_)"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'voting_clf__colsample_bytree': 0.5679080291606311,\n",
              " 'voting_clf__eta': 0.25669249083545453,\n",
              " 'voting_clf__gamma': 0.3664509736859072,\n",
              " 'voting_clf__learning_rate': 0.14474841574499428,\n",
              " 'voting_clf__max_depth': 20,\n",
              " 'voting_clf__min_child_weight': 2,\n",
              " 'voting_clf__n_estimators': 704,\n",
              " 'voting_clf__reg_alpha': 0,\n",
              " 'voting_clf__reg_lambda': 0.1,\n",
              " 'voting_clf__scale_pos_weight': 8,\n",
              " 'voting_clf__subsample': 0.9858685418924441}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    }
  ]
}