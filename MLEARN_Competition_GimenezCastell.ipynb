{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLEARN_Competition_GimenezCastell.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QzW43GdlCXoF",
        "Wn4TROMqCcUY",
        "uMVDRYGJBkgO"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzW43GdlCXoF"
      },
      "source": [
        "# Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdfF9Rz4nS1i"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import sklearn.tree\n",
        "import sklearn.ensemble\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvdFxXlkwPIz",
        "outputId": "9755d906-3ca3-4385-8879-2c451484f02b"
      },
      "source": [
        "# Clone repository in order to get access locally to the datasets\n",
        "!rm -rf .git README.md\n",
        "!git clone -b playing-emsembled-methods https://github.com/sergio-gimenez/anomaly-4G-detection "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'anomaly-4G-detection' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkZG0vkAQiRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5afe5d92-7530-4f6b-87cf-d2485227d26d"
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8104\n",
            "drwxr-xr-x 1 root root    4096 Dec 31 11:52 .\n",
            "drwxr-xr-x 1 root root    4096 Dec 31 10:07 ..\n",
            "drwxr-xr-x 4 root root    4096 Dec 31 11:52 anomaly-4G-detection\n",
            "drwxr-xr-x 1 root root    4096 Dec 21 17:29 .config\n",
            "drwxr-xr-x 1 root root    4096 Dec 21 17:29 sample_data\n",
            "-rw-r--r-- 1 root root 8276307 Dec 31 11:20 voting_model.joblib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiO_tVqEtbhr"
      },
      "source": [
        "train = pd.read_csv('anomaly-4G-detection/ML-MATT-CompetitionQT2021_train.csv', sep=';')\n",
        "test = pd.read_csv('anomaly-4G-detection/ML-MATT-CompetitionQT2021_test.xls', sep=';' )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pQIAxp_wxGk"
      },
      "source": [
        "# Separate labels from data \n",
        "X = train.drop('Unusual', axis='columns')#.to_numpy()\n",
        "y = train['Unusual']#.to_numpy()\n",
        "\n",
        "# We split the data into training and validation subsets (80% and 20%) in\n",
        "# order to validate our training\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X, y, \n",
        "                                                                train_size=0.8,\n",
        "                                                                random_state=1, stratify = y)\n",
        "X_test = test"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkMgA0YsluhJ"
      },
      "source": [
        "#Refactor time feature to minuts and cellName to unique identifier 1:1\n",
        "def getTimeInMinutes(x):\n",
        "  hh, mm  = x.split(\":\")\n",
        "  return int(hh)* 60 + int(mm)\n",
        "\n",
        "def createCellNameDictionary(data):\n",
        "  cellList = []\n",
        "  for i in data[\"CellName\"]:\n",
        "    cellList.append(i)\n",
        "  cellList = set(cellList)\n",
        "  cellDict = {}\n",
        "  for idx, value in enumerate(cellList):\n",
        "    cellDict[value]=idx\n",
        "  return cellDict\n",
        "\n",
        "def refactorFeaturesDataframe(data):\n",
        "  data[\"Time\"] = data[\"Time\"].apply(lambda x: getTimeInMinutes(x))\n",
        "  cellNameDict = createCellNameDictionary(data);\n",
        "  data[\"CellName\"] = data[\"CellName\"].apply(lambda x: cellNameDict[x])\n",
        "  return data\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIoTgjuA0yak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904fbb5b-a488-403f-dd3f-8e99a6cff098"
      },
      "source": [
        "#Refactoring data from features to useful values\n",
        "X_train = refactorFeaturesDataframe(X_train).to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "\n",
        "X_validation = refactorFeaturesDataframe(X_validation).to_numpy()\n",
        "y_validation = y_validation.to_numpy()\n",
        "\n",
        "X_test = refactorFeaturesDataframe(test).to_numpy()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn4TROMqCcUY"
      },
      "source": [
        "# Solving the Classification Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSk27jtY2xyB"
      },
      "source": [
        "clf = sklearn.tree.DecisionTreeClassifier(random_state=1)\n",
        "pipe = Pipeline(steps=[('std_slc', StandardScaler()),\n",
        "                           ('dec_tree', clf)])\n",
        "\n",
        "n_components = list(range(1,X_train.shape[1]+1,2))\n",
        "criterion = ['gini', 'entropy']\n",
        "max_depth = [None,2,8,12]\n",
        "min_samples_split = [2,4,8,10]\n",
        "min_samples_leaf = [1,2,5]\n",
        "\n",
        "parameters = dict(dec_tree__criterion=criterion,\n",
        "                      dec_tree__min_samples_split=min_samples_split,\n",
        "                      dec_tree__min_samples_leaf=min_samples_leaf,\n",
        "                      dec_tree__max_depth=max_depth)\n",
        "#clf_GS = GridSearchCV(pipe, parameters)\n",
        "#clf_GS.fit(X_train, y_train)\n",
        "\n",
        "#clf.fit(X_train, y_train)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6s3bW7121UD"
      },
      "source": [
        "#pred_train = clf_GS.predict(X_train)\n",
        "#pred_val = clf_GS.predict(X_validation)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P31bEittujim"
      },
      "source": [
        "# Voting Classifier with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHDdmOgCuo_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "834d0bd1-c5ef-4be6-aa7b-80b64a0bdc8a"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from joblib import dump, load\n",
        "from google.colab import files\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "#if performVoting == 'y':\n",
        "  \n",
        "try:\n",
        "  clf_GS = load('anomaly-4G-detection/voting_model.joblib') \n",
        "  \n",
        "\n",
        "except:\n",
        "  voting_clf = VotingClassifier( estimators=[ \n",
        "      ('xgb', XGBClassifier(random_state=1, eta=0.10, max_depth=15, min_child_weight=1, n_estimators=400)),\n",
        "      ('dt', DecisionTreeClassifier(random_state=1, criterion='entropy', min_samples_leaf=2)),\n",
        "      ('knn', KNeighborsClassifier(metric=\"euclidean\", weights=\"uniform\", p = 1, n_neighbors=19))\n",
        "      ], voting='soft')\n",
        "  \n",
        "  pipe = Pipeline(steps=[('std_slc', StandardScaler()),\n",
        "                              ('voting_clf', voting_clf)])\n",
        "\n",
        "  #Params ADA\n",
        "  n_estimators_ada = [600, 800]\n",
        "  learning_rate = [0.1,1,10]\n",
        "  #Params Decision Tree\n",
        "  min_samples_split_dt = [2,10,14]\n",
        "  min_samples_leaf_dt = [1,2,5]\n",
        "  #Params GradientBoost\n",
        "  parameters = {\n",
        "  #  'voting_clf__xgb__learning_rate' : [ 0.01, 0.1, 0.5],\n",
        "  # 'voting_clf__xgb__gamma' : [ 0.1, 0.5],\n",
        "    'voting_clf__xgb__eta'    : uniform(0.1, 0.3) ,\n",
        "    \"voting_clf__xgb__colsample_bytree\": uniform(0.7, 0.3),\n",
        "    \"voting_clf__xgb__gamma\": uniform(0, 0.5),\n",
        "    \"voting_clf__xgb__learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
        "    \"voting_clf__xgb__max_depth\": randint(2, 20), # default 3\n",
        "    \"voting_clf__xgb__n_estimators\": randint(100, 1000), # default 100\n",
        "    \"voting_clf__xgb__subsample\": uniform(0.6, 0.4)\n",
        "    }\n",
        "  \n",
        "\n",
        "  '''\n",
        "  parameters = dict(voting_clf__ada__n_estimators=n_estimators_ada,\n",
        "                    voting_clf__decision_tree__min_samples_split = min_samples_split_dt,\n",
        "                      )\n",
        "  '''\n",
        "  #clf_GS = GridSearchCV(estimator=pipe, param_grid=parameters, n_jobs=10, verbose=1, )\n",
        "  clf_GS = RandomizedSearchCV(estimator=pipe, param_distributions=parameters, n_jobs=10, verbose=1, cv=3 )\n",
        "  clf_GS.fit(X_train,y_train)\n",
        "\n",
        "  #Save the model in a file and download locally.\n",
        "  dump(clf_GS, 'voting_model.joblib')\n",
        "  files.download('voting_model.joblib') "
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done  30 out of  30 | elapsed: 10.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f109baf4-d720-418c-a541-1e25f5fe60c9\", \"voting_model.joblib\", 7544319)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViBwqQEApm5V",
        "outputId": "4324829a-3c3b-482e-8946-5b4c2acbf145",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = range(100, 900, 200)\n",
        "print(a)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(100, 900, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6XZezYqNpOh"
      },
      "source": [
        "pred_train = clf_GS.predict(X_train)\n",
        "pred_val = clf_GS.predict(X_validation)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luMnqSly3KZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "406292bd-8e73-4d2f-90ee-d0c20b10b25e"
      },
      "source": [
        "print(\"TRAINING\\n\" + classification_report(y_train, pred_train))\n",
        "print(\"\\nTESTING\\n\" + classification_report(y_validation, pred_val))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     21377\n",
            "           1       1.00      1.00      1.00      8146\n",
            "\n",
            "    accuracy                           1.00     29523\n",
            "   macro avg       1.00      1.00      1.00     29523\n",
            "weighted avg       1.00      1.00      1.00     29523\n",
            "\n",
            "\n",
            "TESTING\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99      5344\n",
            "           1       0.99      0.93      0.96      2037\n",
            "\n",
            "    accuracy                           0.98      7381\n",
            "   macro avg       0.98      0.96      0.97      7381\n",
            "weighted avg       0.98      0.98      0.98      7381\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ3k3xOb3j2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d1dc59-f5f7-4259-f8a6-be1a6158bd19"
      },
      "source": [
        "train_error = 1. - accuracy_score(y_train, pred_train)\n",
        "train_cmat = confusion_matrix(y_train, pred_train)\n",
        "val_error = 1. - accuracy_score(y_validation, pred_val)\n",
        "val_cmat = confusion_matrix(y_validation, pred_val)\n",
        "\n",
        "print('train error: %f ' % train_error)\n",
        "print('train confusion matrix:')\n",
        "print(train_cmat)\n",
        "print('test error: %f ' % val_error)\n",
        "print('test confusion matrix:')\n",
        "print(val_cmat)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train error: 0.000203 \n",
            "train confusion matrix:\n",
            "[[21377     0]\n",
            " [    6  8140]]\n",
            "test error: 0.020187 \n",
            "test confusion matrix:\n",
            "[[5334   10]\n",
            " [ 139 1898]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tbj-UBH5Piz"
      },
      "source": [
        "pred_test = clf_GS.predict(X_test)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMVDRYGJBkgO"
      },
      "source": [
        "# Submission Formatting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H-d7HbGA1I2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d955baf-9dcd-419e-e5f3-edd509d41e0a"
      },
      "source": [
        "%%shell\n",
        "# Create submission file if it does not exists\n",
        "file=predictions.csv\n",
        "if [ ! -e \"$file\" ] ; then\n",
        "    touch anomaly-4G-detection/\"$file\"\n",
        "fi"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9CouZll67HG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "578ad2e6-8b33-4d25-92be-348fe86f0275"
      },
      "source": [
        "# Create index column in data frame object\n",
        "submission_dataframe = pd.DataFrame(np.arange(1, 9159), columns=['Id']) \n",
        "\n",
        "# Append predictions of test data as column\n",
        "submission_dataframe['Label'] = pred_test\n",
        "\n",
        "# Convert Data Frame object to CSV\n",
        "submission_dataframe.to_csv('predictions.csv', index=False)\n",
        "\n",
        "!mv predictions.csv anomaly-4G-detection/\n",
        "predictions = pd.read_csv('anomaly-4G-detection/predictions.csv')\n",
        "predictions"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9153</th>\n",
              "      <td>9154</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9154</th>\n",
              "      <td>9155</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9155</th>\n",
              "      <td>9156</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9156</th>\n",
              "      <td>9157</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9157</th>\n",
              "      <td>9158</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9158 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Id  Label\n",
              "0        1      0\n",
              "1        2      0\n",
              "2        3      0\n",
              "3        4      0\n",
              "4        5      1\n",
              "...    ...    ...\n",
              "9153  9154      0\n",
              "9154  9155      1\n",
              "9155  9156      0\n",
              "9156  9157      0\n",
              "9157  9158      0\n",
              "\n",
              "[9158 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWZoB4CM4Qbo"
      },
      "source": [
        "#!rm anomaly-4G-detection/predictions.csv"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASKJSoDN6Hhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff74dbe2-b3fe-450f-f346-d4383cf0b08c"
      },
      "source": [
        "clf_GS.best_params_"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'voting_clf__xgb__colsample_bytree': 0.7724263008699148,\n",
              " 'voting_clf__xgb__eta': 0.213906480983464,\n",
              " 'voting_clf__xgb__gamma': 0.17010585845471338,\n",
              " 'voting_clf__xgb__learning_rate': 0.2589374262950261,\n",
              " 'voting_clf__xgb__max_depth': 7,\n",
              " 'voting_clf__xgb__n_estimators': 260,\n",
              " 'voting_clf__xgb__subsample': 0.858426551076145}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    }
  ]
}